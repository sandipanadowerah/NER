NER Task Results

1) System A1
	{'test_loss': 0.002970287809148431,
 'test_ANIM': {'precision': 0.7268041237113402,
  'recall': 0.7911471321695761,
  'f1': 0.7576119402985074,
  'number': 3208},
 'test_BIO': {'precision': 0.6363636363636364,
  'recall': 0.875,
  'f1': 0.7368421052631579,
  'number': 16},
 'test_CEL': {'precision': 0.85,
  'recall': 0.8292682926829268,
  'f1': 0.8395061728395061,
  'number': 82},
 'test_DIS': {'precision': 0.7767857142857143,
  'recall': 0.8044914134742405,
  'f1': 0.7903958468526933,
  'number': 1514},
 'test_EVE': {'precision': 0.9690140845070423,
  'recall': 0.9772727272727273,
  'f1': 0.9731258840169732,
  'number': 704},
 'test_FOOD': {'precision': 0.6703296703296703,
  'recall': 0.6466431095406361,
  'f1': 0.658273381294964,
  'number': 1132},
 'test_INST': {'precision': 0.8461538461538461,
  'recall': 0.9166666666666666,
  'f1': 0.8799999999999999,
  'number': 24},
 'test_LOC': {'precision': 0.9954212454212454,
  'recall': 0.9945105215004575,
  'f1': 0.9949656750572082,
  'number': 24046},
 'test_MEDIA': {'precision': 0.9760869565217392,
  'recall': 0.980349344978166,
  'f1': 0.9782135076252723,
  'number': 916},
 'test_MYTH': {'precision': 0.8285714285714286,
  'recall': 0.90625,
  'f1': 0.8656716417910447,
  'number': 64},
 'test_ORG': {'precision': 0.9830815709969789,
  'recall': 0.9836759371221282,
  'f1': 0.9833786642490179,
  'number': 6616},
 'test_PER': {'precision': 0.9944992412746586,
  'recall': 0.9958214624881292,
  'f1': 0.9951599126886213,
  'number': 10530},
 'test_PLANT': {'precision': 0.6701461377870563,
  'recall': 0.7181208053691275,
  'f1': 0.693304535637149,
  'number': 1788},
 'test_TIME': {'precision': 0.8571428571428571,
  'recall': 0.8512110726643599,
  'f1': 0.8541666666666666,
  'number': 578},
 'test_VEHI': {'precision': 0.9032258064516129,
  'recall': 0.875,
  'f1': 0.8888888888888888,
  'number': 64},
 'test_overall_precision': 0.9469450889404486,
 'test_overall_recall': 0.955032955032955,
 'test_overall_f1': 0.9509718257897904,
 'test_overall_accuracy': 0.9901851451624523,
 'test_runtime': 432.7596,
 'test_samples_per_second': 84.684,
 'test_steps_per_second': 10.586}
 
 2) System A2:
 
 {'test_loss': 0.010055127553641796,
 'test_ANIM': {'precision': 0.9365159795866662,
  'recall': 0.93042071197411,
  'f1': 0.9334583957142084,
  'number': 55620},
 'test_BIO': {'precision': 0.6917084028937117,
  'recall': 0.7754210854647536,
  'f1': 0.7311764705882353,
  'number': 3206},
 'test_CEL': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 16},
 'test_DIS': {'precision': 0.6904761904761905,
  'recall': 0.7073170731707317,
  'f1': 0.6987951807228916,
  'number': 82},
 'test_EVE': {'precision': 0.70828025477707,
  'recall': 0.7354497354497355,
  'f1': 0.7216093445814407,
  'number': 1512},
 'test_FOOD': {'precision': 0.9241573033707865,
  'recall': 0.9346590909090909,
  'f1': 0.9293785310734464,
  'number': 704},
 'test_INST': {'precision': 0.6076555023923444,
  'recall': 0.450354609929078,
  'f1': 0.5173116089613033,
  'number': 1128},
 'test_LOC': {'precision': 0.6666666666666666,
  'recall': 0.3333333333333333,
  'f1': 0.4444444444444444,
  'number': 24},
 'test_MEDIA': {'precision': 0.9602027251578598,
  'recall': 0.961800932090546,
  'f1': 0.9610011641443539,
  'number': 24032},
 'test_MYTH': {'precision': 0.9311827956989247,
  'recall': 0.9454148471615721,
  'f1': 0.9382448537378115,
  'number': 916},
 'test_ORG': {'precision': 0.9482915028726943,
  'recall': 0.9485783424077435,
  'f1': 0.948434900952669,
  'number': 6612},
 'test_PER': {'precision': 0.9888151658767772,
  'recall': 0.990693257359924,
  'f1': 0.9897533206831118,
  'number': 10530},
 'test_PLANT': {'precision': 0.5614035087719298,
  'recall': 0.6901248581157775,
  'f1': 0.6191446028513238,
  'number': 1762},
 'test_TIME': {'precision': 0.7664233576642335,
  'recall': 0.726643598615917,
  'f1': 0.7460035523978686,
  'number': 578},
 'test_VEHI': {'precision': 0.7083333333333334,
  'recall': 0.53125,
  'f1': 0.6071428571428571,
  'number': 64},
 'test_overall_precision': 0.9246686730097015,
 'test_overall_recall': 0.9264697619538141,
 'test_overall_f1': 0.9255683412854335,
 'test_overall_accuracy': 0.9618096678913622,
 'test_runtime': 259.9977,
 'test_samples_per_second': 128.886,
 'test_steps_per_second': 16.112}
 
 3) System B1
 {'test_loss': 0.0008827725541777909,
 'test_ANIM': {'precision': 0.6895119418483905,
  'recall': 0.8310387984981227,
  'f1': 0.7536889897843361,
  'number': 1598},
 'test_ORG': {'precision': 0.9899224806201551,
  'recall': 0.9849595063632858,
  'f1': 0.987434757394162,
  'number': 5186},
 'test_PER': {'precision': 0.9944898346950408,
  'recall': 0.9941120607787275,
  'f1': 0.9943009118541034,
  'number': 10530},
 'test_overall_precision': 0.9598001362707245,
 'test_overall_recall': 0.9763197412498557,
 'test_overall_f1': 0.9679894634369811,
 'test_overall_accuracy': 0.9980981197320078,
 'test_runtime': 428.7858,
 'test_samples_per_second': 85.469,
 'test_steps_per_second': 10.684}
 
 4) System C1
 {'test_loss': 0.0009240027866326272,
 'test_ANIM': {'precision': 0.6683366733466933,
  'recall': 0.8347934918648311,
  'f1': 0.7423483583750695,
  'number': 1598},
 'test_ORG': {'precision': 0.9891682785299807,
  'recall': 0.9861164674122638,
  'f1': 0.9876400154499807,
  'number': 5186},
 'test_PER': {'precision': 0.9927921092564491,
  'recall': 0.9941120607787275,
  'f1': 0.9934516465787226,
  'number': 10530},
 'test_overall_precision': 0.955166572557877,
 'test_overall_recall': 0.9770128219937623,
 'test_overall_f1': 0.9659661946094107,
 'test_overall_accuracy': 0.9979742093509113,
 'test_runtime': 427.331,
 'test_samples_per_second': 85.76,
 'test_steps_per_second': 10.72}
 
 5) System B2
 {'test_loss': 0.0019564079120755196,
 'test_ANIM': {'precision': 0.9541807432432432,
  'recall': 0.9468831849135673,
  'f1': 0.9505179576168691,
  'number': 19090},
 'test_DIS': {'precision': 0.9882686849574267,
  'recall': 0.992022792022792,
  'f1': 0.9901421800947867,
  'number': 10530},
 'test_LOC': {'precision': 0.9491590214067278,
  'recall': 0.957578094870806,
  'f1': 0.9533499712036858,
  'number': 5186},
 'test_ORG': {'precision': 0.6274509803921569,
  'recall': 0.7804878048780488,
  'f1': 0.6956521739130435,
  'number': 82},
 'test_PER': {'precision': 0.8181818181818182,
  'recall': 0.6923076923076923,
  'f1': 0.7500000000000001,
  'number': 26},
 'test_overall_precision': 0.962718669343275,
 'test_overall_recall': 0.9615054133012545,
 'test_overall_f1': 0.9621116588329702,
 'test_overall_accuracy': 0.9903090555435488,
 'test_runtime': 242.9603,
 'test_samples_per_second': 137.924,
 'test_steps_per_second': 17.242}
 
 6) System C2
 
 {'test_loss': 0.002072758274152875,
 'test_ANIM': {'precision': 0.9456924979389942,
  'recall': 0.9614457831325302,
  'f1': 0.953504078133929,
  'number': 19090},
 'test_DIS': {'precision': 0.990719696969697,
  'recall': 0.9935422602089269,
  'f1': 0.9921289710763395,
  'number': 10530},
 'test_LOC': {'precision': 0.9533995416348358,
  'recall': 0.9625915927497107,
  'f1': 0.9579735175590097,
  'number': 5186},
 'test_ORG': {'precision': 0.6470588235294118,
  'recall': 0.8048780487804879,
  'f1': 0.717391304347826,
  'number': 82},
 'test_PER': {'precision': 0.9090909090909091,
  'recall': 0.7692307692307693,
  'f1': 0.8333333333333333,
  'number': 26},
 'test_overall_precision': 0.9594089673913043,
 'test_overall_recall': 0.9707853583089878,
 'test_overall_f1': 0.9650636371401724,
 'test_overall_accuracy': 0.991386787695411,
 'test_runtime': 282.0826,
 'test_samples_per_second': 118.795,
 'test_steps_per_second': 14.85}